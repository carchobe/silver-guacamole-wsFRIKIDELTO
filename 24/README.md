# 024 Web Scraping 3: SELENIUM y BEAUTIFULSOUP [curso Python]

[024 Web Scraping 3: SELENIUM y BEAUTIFULSOUP [curso Python]](https://www.youtube.com/watch?v=v_LUqyKFN_s&list=PLheIVUbpfWZ1AVQHaPq5iwRMf6JcI6xP0&index=3)

## Requisitos

Anaconda

## Descripcion

[https://www.youtube.com/watch?v=v_LUqyKFN_s&list=PLheIVUbpfWZ1AVQHaPq5iwRMf6JcI6xP0&index=3](https://www.youtube.com/watch?v=v_LUqyKFN_s&list=PLheIVUbpfWZ1AVQHaPq5iwRMf6JcI6xP0&index=3)

En este v√≠deo veremos que con la librer√≠a REQUESTS no siempre lograremos realizar una petici√≥n que nos devuelva una respuesta satisfactoria. Aprenderemos a qu√© es debido esto y c√≥mo solucionarlo con la librer√≠a SELENIUM. Veremos lo m√°s b√°sico de esta √∫ltima para poder recibir la respuesta deseada del servidor y as√≠ lograr crear una buena sopa con BEAUTIFULSOUP.

Programaci√≥n FRONT-END y BACK-END:

[https://www.um.es/docencia/barzana/DAWEB/2017-18/daweb-tema-13-paginas-web-dinamicas.html](https://www.um.es/docencia/barzana/DAWEB/2017-18/daweb-tema-13-paginas-web-dinamicas.html)

[https://openwebinars.net/blog/paginas-web-estaticas-vs-paginas-web-dinamicas/](https://openwebinars.net/blog/paginas-web-estaticas-vs-paginas-web-dinamicas/)

Extensi√≥n DISABLE JAVASCRIPT para Chrome:

[https://chrome.google.com/webstore/de...](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqa0p6SGwwVzlpczJrOC1VTkFCb09fc1hmR3dQQXxBQ3Jtc0trUWtTM01YcF9IN2xzOTVvUDlXcm14UmQyZnVTVVpQOVQyNnB0YkVpSkZ4ZTlFYVQtWnR3MkF4d2huWk5jcUlzOXdxczlSbjN1bDBLMkVjalZnaXpzNVpabXNyWno1dFoyb3cyX1VxY0MydVhiRzREcw&q=https%3A%2F%2Fchrome.google.com%2Fwebstore%2Fdetail%2Fdisable-javascript%2Fjfpdlihdedhlmhlbgooailmfhahieoem&v=v_LUqyKFN_s)

WEBDRIVER-MANAGER:

[https://github.com/SergeyPirogov/webd...](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbUhfX3dXRlFva3R6T3lPdUZhblhGVUZSdFNDQXxBQ3Jtc0tsYmFCdzU5clJ1cl9hZkkxc1pSci1LX0Q4eTRZYWtKT3VybDZ3UXN1UTlmUGNXNEUxTFEzQk5fMzVwNnE0YzdCMjRsM094YnZ3aFlqYjQyMHdybVVfOWFTc1Q5ejF3Qm1NUE5xSkNaWG5qYzhjNEhLUQ&q=https%3A%2F%2Fgithub.com%2FSergeyPirogov%2Fwebdriver_manager&v=v_LUqyKFN_s)

SELENIUM:

[https://selenium-python.readthedocs.io](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqa3phUE1KNVFJQVcxOWJJaEt0NF9tTGY4WndUQXxBQ3Jtc0ttMkYzWngtQVhLMm1BYlhaQ1pyZkFRTFlaOTJaTUZuUGtUWjh4cmNTSFIxamY3OUtGMkNfQi0wZHZwMU1GNV9XZ3ZGWFFfQmNxRXBMd0wtZGxUaVgxZ0FfVTlQNXJFNlNIRG9OaElCaWk1SU1fWngxVQ&q=https%3A%2F%2Fselenium-python.readthedocs.io%2F&v=v_LUqyKFN_s)

√çNDICE:

[00:00](https://www.youtube.com/watch?v=v_LUqyKFN_s&list=PLheIVUbpfWZ1AVQHaPq5iwRMf6JcI6xP0&index=3&t=0s) Introducci√≥n

[00:19](https://www.youtube.com/watch?v=v_LUqyKFN_s&list=PLheIVUbpfWZ1AVQHaPq5iwRMf6JcI6xP0&index=3&t=19s) Los mejores canales de Telegram

[00:38](https://www.youtube.com/watch?v=v_LUqyKFN_s&list=PLheIVUbpfWZ1AVQHaPq5iwRMf6JcI6xP0&index=3&t=38s) P√°ginas web est√°ticas y p√°ginas web din√°micas

[01:41](https://www.youtube.com/watch?v=v_LUqyKFN_s&list=PLheIVUbpfWZ1AVQHaPq5iwRMf6JcI6xP0&index=3&t=101s) ¬øCu√°ndo no funciona la librer√≠a REQUESTS?

[02:40](https://www.youtube.com/watch?v=v_LUqyKFN_s&list=PLheIVUbpfWZ1AVQHaPq5iwRMf6JcI6xP0&index=3&t=160s) Extensi√≥n para Chrome: Disable JavaScript

[06:07](https://www.youtube.com/watch?v=v_LUqyKFN_s&list=PLheIVUbpfWZ1AVQHaPq5iwRMf6JcI6xP0&index=3&t=367s) Problemas con CloudFlare

[07:37](https://www.youtube.com/watch?v=v_LUqyKFN_s&list=PLheIVUbpfWZ1AVQHaPq5iwRMf6JcI6xP0&index=3&t=457s) ¬øQu√© es Selenium?

[09:51](https://www.youtube.com/watch?v=v_LUqyKFN_s&list=PLheIVUbpfWZ1AVQHaPq5iwRMf6JcI6xP0&index=3&t=591s) C√≥mo instalar Webdriver Manager

[10:00](https://www.youtube.com/watch?v=v_LUqyKFN_s&list=PLheIVUbpfWZ1AVQHaPq5iwRMf6JcI6xP0&index=3&t=600s) C√≥mo instalar Selenium

[10:13](https://www.youtube.com/watch?v=v_LUqyKFN_s&list=PLheIVUbpfWZ1AVQHaPq5iwRMf6JcI6xP0&index=3&t=613s) C√≥mo hacer web scraping con SELENIUM

[15:38](https://www.youtube.com/watch?v=v_LUqyKFN_s&list=PLheIVUbpfWZ1AVQHaPq5iwRMf6JcI6xP0&index=3&t=938s) Programa de ejemplo con SELENIUM

[17:01](https://www.youtube.com/watch?v=v_LUqyKFN_s&list=PLheIVUbpfWZ1AVQHaPq5iwRMf6JcI6xP0&index=3&t=1021s) Conclusiones y despedida

## Contenido

√çNDICE:

- [00:00](https://www.youtube.com/watch?v=v_LUqyKFN_s&list=PLheIVUbpfWZ1AVQHaPq5iwRMf6JcI6xP0&index=3&t=0s) Introducci√≥n
    
    el problema es JavaScript
    
- [00:19](https://www.youtube.com/watch?v=v_LUqyKFN_s&list=PLheIVUbpfWZ1AVQHaPq5iwRMf6JcI6xP0&index=3&t=19s) Los mejores canales de Telegram
- [00:38](https://www.youtube.com/watch?v=v_LUqyKFN_s&list=PLheIVUbpfWZ1AVQHaPq5iwRMf6JcI6xP0&index=3&t=38s) P√°ginas web est√°ticas y p√°ginas web din√°micas
    - Las estaticas es fijo. el HTML esta en el server
    - Las dinamicas son plantillas con algumos datos fijos en el server. se envia la plantilla y se llena lo demas de dos maneras
    - la primera es que el server completa la plantilla pidiendole a una base de datos los datos que faltan y se lo envia al cliente. este es el metodo BACKEND aqui equest funciona bien.
- [01:41](https://www.youtube.com/watch?v=v_LUqyKFN_s&list=PLheIVUbpfWZ1AVQHaPq5iwRMf6JcI6xP0&index=3&t=101s) ¬øCu√°ndo no funciona la librer√≠a REQUESTS? üîó
    - la segunda manera es el metodo FRONTEND. el server nos envia la plantilla que tiene los codigos JavaScript para llenar los datos faltantes en la maquina del cliente. Los navegadores detectan el codigo y automaticamente se ejecuta y pidiendo lo que haga falta. Aqui request NO SIRVE porque solo nos daria la plantilla HTML
    - [https://www.um.es/docencia/barzana/DAWEB/2017-18/daweb-tema-13-paginas-web-dinamicas.html](https://www.um.es/docencia/barzana/DAWEB/2017-18/daweb-tema-13-paginas-web-dinamicas.html)
    - [https://openwebinars.net/blog/paginas-web-estaticas-vs-paginas-web-dinamicas/](https://openwebinars.net/blog/paginas-web-estaticas-vs-paginas-web-dinamicas/)
    - para solucionar esto tenemos SELENIUM que es para el frotnend
- [02:40](https://www.youtube.com/watch?v=v_LUqyKFN_s&list=PLheIVUbpfWZ1AVQHaPq5iwRMf6JcI6xP0&index=3&t=160s) Extensi√≥n para Chrome: Disable JavaScript üîó
    - Pero antes de codear, es bueno inspeccionar la pagina primero. Los datos que quieres se generan en el codigo JavaScript?
    - Aqui puedes usar request para obtener la respuesta en HTML.
    - solo usa selenium is request no sirve
    - hay otra opcion que es usar DISABLE JAVASCRIPT para desactivar el javascript de la pagina üîó [https://chromewebstore.google.com/detail/disable-javascript/jfpdlihdedhlmhlbgooailmfhahieoem?pli=1](https://chromewebstore.google.com/detail/disable-javascript/jfpdlihdedhlmhlbgooailmfhahieoem?pli=1)
    - [https://addons.mozilla.org/es/firefox/addon/disable-javascript/](https://addons.mozilla.org/es/firefox/addon/disable-javascript/)
    - ‚ùï(BONUS) ADICIONALMENTE si estas en firefox puedes entrar a `about:config` y buscar el flag `javascript.enabled` y cambiarlo a `False`. esto lo desactivara de manera global
    - ‚ùï(BONUS) ADICIONALMENTE puedes en chrome desactivar javascript asi: en la pagina abre las DevTools con f12> si estas en windos o linux presiona `CTRL + SHIFT + p` y te saldra una terminal, tipea javascript y te saldra la opcion de inhabilitarlo
    - si desahabilitas javascript en la web y puedes ver el contenido, puden haber dos razones
    - la info que quieres esta en la plantilla HTML
    - la info que quieres esta en el server y completa los datos por ti (Metodo BACKEND)
    - en [game.es](http://game.es) los resultados se cargan en javascript por ejemplo.
- [06:07](https://www.youtube.com/watch?v=v_LUqyKFN_s&list=PLheIVUbpfWZ1AVQHaPq5iwRMf6JcI6xP0&index=3&t=367s) Problemas con CloudFlare üîó
    - en pccomponentes, lo que necesitamos no esta en Javascript, puedes usar request. pero hay un problema
    - tendremos un codigo html `403 Forbidden`
    - (bonus) [https://gabicuesta.blogspot.com/2019/01/http-status-codes.html](https://gabicuesta.blogspot.com/2019/01/http-status-codes.html) üîó
    - es porque cloudflare detecta que somos un bot. poto cloudflare.
    - 
- [07:37](https://www.youtube.com/watch?v=v_LUqyKFN_s&list=PLheIVUbpfWZ1AVQHaPq5iwRMf6JcI6xP0&index=3&t=457s) ¬øQu√© es Selenium?
    - En realidad no fue disenado para web scraping. esta pensado para desarrollar programas web
    - pero la mayoria de las funciones que tiene nos vienen de perlas para web scraping
    - puedes instalar chromedriver, pero esta es la manera manual
- [09:51](https://www.youtube.com/watch?v=v_LUqyKFN_s&list=PLheIVUbpfWZ1AVQHaPq5iwRMf6JcI6xP0&index=3&t=591s) C√≥mo instalar Webdriver Manager ‚≠ê üîó
    
    [Instalacion y configuracion de Selenium üìñ](https://www.notion.so/Instalacion-y-configuracion-de-Selenium-d9d20ce4f1a144bab18ea54d9b9ea31e?pvs=21) 
    
    - [https://github.com/carchobe/webscraping-platzi](https://github.com/carchobe/webscraping-platzi)
    - [https://github.com/carchobe/webscraping-platzi/blob/main/web/Clases/M√≥dulo 3%3A Scraping con Selenium/M3C9. Comentarios finales (copia Firefox).ipynb](https://github.com/carchobe/webscraping-platzi/blob/main/web/Clases/M%C3%B3dulo%203%3A%20Scraping%20con%20Selenium/M3C9.%20Comentarios%20finales%20(copia%20Firefox).ipynb)
    - [https://github.com/carchobe/webscraping-platzi/blob/main/web/Clases/M√≥dulo 3%3A Scraping con Selenium/M3C9. Comentarios finales.ipynb](https://github.com/carchobe/webscraping-platzi/blob/main/web/Clases/M%C3%B3dulo%203%3A%20Scraping%20con%20Selenium/M3C9.%20Comentarios%20finales.ipynb)
    - [https://www.selenium.dev/blog/2022/introducing-selenium-manager/](https://www.selenium.dev/blog/2022/introducing-selenium-manager/) üîó
    
    ---
    
    ```bash
    pip install webdriver-manager
    ```
    
- [10:00](https://www.youtube.com/watch?v=v_LUqyKFN_s&list=PLheIVUbpfWZ1AVQHaPq5iwRMf6JcI6xP0&index=3&t=600s) C√≥mo instalar Selenium
    
    ```bash
    pip install selenium
    ```
    
    BONUS
    
    ```bash
    conda -n wsfrikideto -c conda-forge selenium
    ```
    
- [10:13](https://www.youtube.com/watch?v=v_LUqyKFN_s&list=PLheIVUbpfWZ1AVQHaPq5iwRMf6JcI6xP0&index=3&t=613s) C√≥mo hacer web scraping con SELENIUM y chrome
    - firefox
        - [https://github.com/carchobe/webscraping-platzi/blob/main/web/Clases/M√≥dulo 3%3A Scraping con Selenium/M3C9. Comentarios finales (copia Firefox).ipynb](https://github.com/carchobe/webscraping-platzi/blob/main/web/Clases/M%C3%B3dulo%203%3A%20Scraping%20con%20Selenium/M3C9.%20Comentarios%20finales%20(copia%20Firefox).ipynb)
        - 
        
        ```python
        #firefox
        from webdriver_manager.firefox import GeckoDriverManager
        from selenium import webdriver
        from selenium.webdriver.firefox.service import Service
        from bs4 import BeautifulSoup
        ```
        
    - ‚ùïGran video. Con selenium 4 creo que ya no hace falta indicar el path de descarga del driver. De hecho da error si lo haces, as√≠ que directamente:
        - `driver = webdriver.Chrome(service=Service(ChromeDriverManager().install())).`
    
    ```python
    from selenium import webdriver
    from webdriver_manager.chrome import ChromeDriverManager
    from selenium.webdriver.chrome.service import Service
    from bs4 import BeautifulSoup
    
    #from selenium.webdriver.chrome.options import Options
    #from selenium.webdriver.chrome.service import Service
    ```
    
    ```python
    #Esto ya no sirve
    ruta = ChromeDriverManager(path="./chromedriver").install
    # ruta del driver al cual llamaremos
    
    #Esto ya no sirve
    ```
    
    ```python
    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))
    #ahora si
    # si haces esto de una vez te salta la ventana de pruebas
    ```
    
    - lo de abajo parece que ya no sirve
    
    ```python
    s = Service(ruta)
    #instanciacion del servicio que a su vez neceita la ruta
    ```
    
    ```python
    driver = webdriver.Chrome(service=s)
    #ahora a instanciar el webdriver de selenium
    ```
    
    - esto si
    - y recuerda tener el javascript desactivado
    
    ```python
    url = "https://www.impactgame.es/epages/63945077.sf/es_ES/?ObjectPath=/Shops/63945077/Products/jm000092"
    ```
    
    ```python
    driver.get(url)
    ```
    
    - ahora a obtener el HTML de la pagina automatizada
    
    ```python
    driver.page_source
    ```
    
    - Ahora a scrapear con BeautifulSoup4
    - hagamos una sopa
    - recuerda que la sopa tiene dos argumentos, el HTML y el parser
    
    ```python
    soup = BeautifulSoup(driver.page_source,'html.parser')
    ```
    
    - ahora a ver el articulo el nombre
    
    ```python
    soup.find('h1',itemprop="name")
    #prueba esto primero
    ```
    
    ```python
    soup.find('h1',itemprop="name").text
    ```
    
    - el precio
    
    ```python
    soup.find('span',itemprop="price").text
    ```
    
    - el precio descontado
    - pues no hay
    - la imagen
    - Aunque esto nos devolvera el el link de la imagen son la url del sitio
    
    ```python
    soup.find('img',itemprop="image").attrs.get('src')
    ```
    
    - para solucionar podiras ponerlo tu mismo
    
    ```python
    URL_BASE = 'https://www.impactgame.es'
    ```
    
    ```python
    URL_BASE + soup.find('img',itemprop="image").attrs.get('src')
    ```
    
    - La ultima sub categoria de la tienda
    - üëá esto tuve que hacerlo asi por que no podia hacerlo como en el video. use find all y como devuelve una lista iterable seleccione directa,ente la categoria
    
    ```python
    soup.find_all('span',itemprop="name")[2].text
    ```
    
    - ahora el codigo de reerencia del producto
    - no hay en la pagina de Impat Games, pero al parecer esta en la URL asi que‚Ä¶
    
    ```python
    product_code = (url[33:41])
    product_code
    ```
    
- [15:38](https://www.youtube.com/watch?v=v_LUqyKFN_s&list=PLheIVUbpfWZ1AVQHaPq5iwRMf6JcI6xP0&index=3&t=938s) Programa de ejemplo con SELENIUM
    - Ahora vamos a correr el programa entero en un script de python
    
    ```python
    # Importamos las librerias
    from selenium import webdriver
    from webdriver_manager.chrome import ChromeDriverManager
    from selenium.webdriver.chrome.service import Service
    from bs4 import BeautifulSoup
    
    # descargamos el driver y abrira la ventana de pruebas de Chrome
    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))
    
    # Asignamos las Variables
    URL_BASE = 'https://www.impactgame.es'
    url = "https://www.impactgame.es/epages/63945077.sf/es_ES/?ObjectPath=/Shops/63945077/Products/jm000092"
    
    # Abrimos la url
    driver.get(url)
    
    # Descargamos y agarramos el codigo HTML cuando se complete la solicitud GET anterior
    driver.page_source
    
    # Listo, hagamos la sopa de BeautifulSoup (el HTML y el parser)
    soup = BeautifulSoup(driver.page_source,'html.parser')
    
    # Pidamos el nombre
    nombre_producto = soup.find('h1',itemprop="name").text
    
    # El precio
    precio = soup.find('span',itemprop="price").text
    
    # La imagen
    imagen_producto = URL_BASE + soup.find('img',itemprop="image").attrs.get('src')
    
    # La ultima sub categoria
    sub_categoria = soup.find_all('span',itemprop="name")[2].text
    
    # Codigo de referencia del producto
    codigo_ref = url[33:41]
    
    # Ahora mostremos los datos obtenidos
    print('NOMBRE DEL PRODUCTO:',nombre_producto)
    print('PRECIO:',precio)
    print('IMAGEN:',imagen_producto)
    print('SUB CATEGORIA:',sub_categoria)
    print('CODIGO:',codigo_ref)
    
    #Cerramos el script scraper
    driver.quit()
    ```
    
- [17:01](https://www.youtube.com/watch?v=v_LUqyKFN_s&list=PLheIVUbpfWZ1AVQHaPq5iwRMf6JcI6xP0&index=3&t=1021s) Conclusiones y despedida
    - esto es solo la punta del Icebrg, se puede lograr mucho mas con selenium
